{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifier\n",
    "\n",
    "\n",
    "Using: http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, make_scorer, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param setting done\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# What set of hyperparamaters to run?\n",
    "RUNSHORT='SHORT'\n",
    "RUNLONG='LONG'\n",
    "RUNBEST='BEST'\n",
    "RUNDEFAULT = 'DEFAULT'\n",
    "\n",
    "\n",
    "# Set this:\n",
    "whatAreWeRunning = RUNBEST\n",
    "\n",
    "# What models are we running?\n",
    "# \n",
    "# These are ALL: [('l1',None),('l2',None),('rfc',None),('gbc',None),('decisiontree',None),('kneighbors',None),\n",
    "#                 ('sgd',None),('bagging',None),('adaboost',None),('gaussiannb',None),\n",
    "#                  ('baggingBE':'l1'),('adaboostBE':'l2')]\n",
    "#\n",
    "# modelList2Run are the classifiers\n",
    "# stackingModelName is the meta-classifier\n",
    "# \n",
    "\n",
    "# stacking meta_classifier\n",
    "stackingModel = ('l2', None)\n",
    "\n",
    "#\n",
    "modelList2Run = [\n",
    "                 ('l2',None),\n",
    "                 ('sgd',None),\n",
    "                 ('gaussiannb',None),\n",
    "                 ('bagging','gbc'),\n",
    "                 ('adaboost','gbc')\n",
    "                ]\n",
    "\n",
    "\n",
    "runs = { \n",
    "        'Name' : (stackingModel, modelList2Run)\n",
    "       }\n",
    "\n",
    "# \n",
    "runLogName = 'stacking 100p'\n",
    "logFileName = 'stacking.csv'\n",
    "#runLogName = 'Final 3of5'\n",
    "#logFileName = 'FinalRun.csv'\n",
    "\n",
    "\n",
    "\n",
    "# Grid search\n",
    "crossValidationSplits = None   # None = len(modelList2Run)+1\n",
    "gridSearchVerbose = 2\n",
    "\n",
    "SMALLDATA = False   # False is the full run of data\n",
    "SMALLDATASIZE = .95  # use 10% of the dataset\n",
    "\n",
    "\n",
    "########## Nothing below this to change #########\n",
    "\n",
    "useStandardScaler = True\n",
    "\n",
    "# Used to selet the number of features to report for feature importance\n",
    "FEATURESTOREPORT = 40\n",
    "\n",
    "goalsToReach = {'AUROC': 0.70,\n",
    "         'Precision': 0.386,\n",
    "         'fbeta': 0.44}\n",
    "\n",
    "# List of base stimator models\n",
    "modelsList= ['l1', 'l2', 'rfc', 'gbc', 'decisiontree', 'kneighbors', 'sgd', \n",
    "             'bagging', 'adaboost', 'gaussiannb']\n",
    "\n",
    "# Other\n",
    "beModels = ['bagging','adaboost']\n",
    "\n",
    "SEED = 42\n",
    "TESTSIZE = 0.25\n",
    "FBETA = 0.25\n",
    "\n",
    "print ('Param setting done')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_SD</th>\n",
       "      <th>addr_state_TN</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11575.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A</td>\n",
       "      <td>72.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>E</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A</td>\n",
       "      <td>84.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term grade  emp_length  annual_inc  loan_status    dti  \\\n",
       "0    11575.0  36.0     A        72.0    153000.0          0.0  16.99   \n",
       "1     7200.0  36.0     E        24.0     50000.0          0.0   6.07   \n",
       "2     7500.0  36.0     A        84.0    110000.0          0.0  13.12   \n",
       "\n",
       "   delinq_2yrs  inq_last_6mths  mths_since_last_delinq  ...  addr_state_SD  \\\n",
       "0          0.0             0.0                    24.0  ...            0.0   \n",
       "1          0.0             0.0                    72.0  ...            0.0   \n",
       "2          0.0             2.0                     0.0  ...            0.0   \n",
       "\n",
       "   addr_state_TN  addr_state_TX  addr_state_UT  addr_state_VA  addr_state_VT  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            1.0            0.0            0.0            0.0   \n",
       "\n",
       "   addr_state_WA  addr_state_WI  addr_state_WV  addr_state_WY  \n",
       "0            0.0            0.0            0.0            0.0  \n",
       "1            1.0            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0            0.0  \n",
       "\n",
       "[3 rows x 139 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the train and test datasets\n",
    "X = pd.read_csv('LendingClub2017_2018FeatureReady.csv.gz',  compression='gzip')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_SD</th>\n",
       "      <th>addr_state_TN</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11575.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A</td>\n",
       "      <td>72.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>E</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>A</td>\n",
       "      <td>84.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term grade  emp_length  annual_inc    dti  delinq_2yrs  \\\n",
       "0    11575.0  36.0     A        72.0    153000.0  16.99          0.0   \n",
       "1     7200.0  36.0     E        24.0     50000.0   6.07          0.0   \n",
       "2     7500.0  36.0     A        84.0    110000.0  13.12          0.0   \n",
       "\n",
       "   inq_last_6mths  mths_since_last_delinq  mths_since_last_record  ...  \\\n",
       "0             0.0                    24.0                    84.0  ...   \n",
       "1             0.0                    72.0                     0.0  ...   \n",
       "2             2.0                     0.0                     0.0  ...   \n",
       "\n",
       "   addr_state_SD  addr_state_TN  addr_state_TX  addr_state_UT  addr_state_VA  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            1.0            0.0            0.0   \n",
       "\n",
       "   addr_state_VT  addr_state_WA  addr_state_WI  addr_state_WV  addr_state_WY  \n",
       "0            0.0            0.0            0.0            0.0            0.0  \n",
       "1            0.0            1.0            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0            0.0            0.0  \n",
       "\n",
       "[3 rows x 138 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep the data\n",
    "#Create new dataframe with dummy features\n",
    "targetVariable = 'loan_status'\n",
    "\n",
    "# Create separate object for input features\n",
    "y = X[targetVariable]\n",
    "\n",
    "# Create separate object for target variable\n",
    "X.drop(targetVariable, axis = 1, inplace=True)\n",
    "\n",
    "X.head(3)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions and Classes\n",
    "CalcScores: Will run the different scores, track them, report, keep a log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookupModelName (name):\n",
    "    modelNames = {'gbc':'gradientboostingclassifier__',\n",
    "                     'l1':'logisticregression__',\n",
    "                     'l2':'logisticregression__',\n",
    "                     'rfc':'randomforestclassifier__',\n",
    "                     'bagging':'baggingclassifier__',\n",
    "                     'adaboost':'adaboostclassifier__',\n",
    "                     'gaussiannb':'gaussiannb__',\n",
    "                     'gpr' : 'gaussianprocessclassifier_',\n",
    "                     'decisiontree':'decisiontreeclassifier__',\n",
    "                     'kneighbors': 'kneighborsclassifier__',\n",
    "                     'sgd':'sgdclassifier__',\n",
    "                     'baggingBE':'baggingclassifier__',\n",
    "                     'adaboostBE':'adaboostclassifier__',\n",
    "                    }\n",
    "    return(modelNames[name])\n",
    "    \n",
    "    \n",
    "class calcScores(object):\n",
    "    def __init__(self, clf, modelName, hyperparameters, hyperparametersBE, X, y, runTime=None, goals=None):\n",
    "\n",
    "        self.clf = clf\n",
    "        self.scores = {}\n",
    "        self.modelName = modelName\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.hyperparametersBE = hyperparametersBE\n",
    "        self.bestParams = None\n",
    "\n",
    "        pred = self.clf.predict(X)\n",
    "        if modelName != 'sgd':\n",
    "            predProba = self.clf.predict_proba(X)\n",
    "            rows, cols = predProba.shape\n",
    "            if cols==2:\n",
    "                aurocPred = [p[1] for p in predProba]\n",
    "            else:\n",
    "                aurocPred = predProba\n",
    "            fpr, tpr, thresholds = roc_curve(y, aurocPred)\n",
    "        \n",
    "        # Test for runtimer\n",
    "        if runTime:\n",
    "            runInMinutes = runTime / 60\n",
    "        else:\n",
    "            runInMinutes = 0\n",
    "\n",
    "        if hasattr(clf,'best_score_'):\n",
    "            bestScore = clf.best_score_\n",
    "        else:\n",
    "            bestScore = 0\n",
    "        if hasattr(clf,'best_params_'):\n",
    "            self.bestParams = clf.best_params_\n",
    "        else:\n",
    "            self.bestParams = hyperparameters\n",
    "            \n",
    "        # Track feature importance\n",
    "        COEF = None\n",
    "        FI = None\n",
    "        if hasattr(self.clf,'feature_importances_'):\n",
    "            FI = self.clf.feature_importances_\n",
    "        if hasattr(self.clf,'coef_'):\n",
    "            COEF = self.clf.coef_[0]\n",
    "\n",
    "     \n",
    "        self.scores = {'fbeta': fbeta_score(y, pred, beta = FBETA), \n",
    "                       'CM': confusion_matrix(y, pred), \n",
    "                       'Recall': recall_score(y, pred),\n",
    "                       'Precision': precision_score(y, pred),\n",
    "                       'RunTime': runInMinutes,\n",
    "                       'F1': f1_score(y, pred),\n",
    "                       'Accuracy': accuracy_score(y, pred),\n",
    "                       'MAE': mean_absolute_error(y, pred),\n",
    "                       'r2': r2_score(y, pred),\n",
    "                       'Best Score': bestScore,\n",
    "                       'Best Params': self.bestParams,\n",
    "                       'FI': FI,\n",
    "                       'COEF': COEF} \n",
    "\n",
    "        if modelName == 'sgd':\n",
    "            self.scores['rocauc_score'] = 0.0\n",
    "            self.scores['AUROC'] = 0.0\n",
    "            self.scores['roc_curve'] = (0.,0.,0.)\n",
    "        else:\n",
    "            self.scores['rocauc_score'] = roc_auc_score(y, aurocPred)\n",
    "            self.scores['AUROC'] = auc(fpr, tpr)\n",
    "            self.scores['roc_curve'] = (fpr, tpr, thresholds)\n",
    "        \n",
    "        \n",
    "        # Test for Goals\n",
    "        listGoals = ''\n",
    "        self.scores['Goals'] = 'Not Reached'\n",
    "        if goalsToReach is not None:\n",
    "            for goal in goalsToReach:\n",
    "                if goal in self.scores:\n",
    "                    if self.scores[goal] is not None:\n",
    "                        val = goalsToReach[goal]\n",
    "                        if self.scores[goal] > val:\n",
    "                            listGoals += '{} of {:5.3f} beats {:5.3f},  '.format(goal,self.scores[goal], val)\n",
    "                if listGoals:\n",
    "                    self.scores['Goals'] = listGoals\n",
    "                    \n",
    "        # Build table for comparison reporting\n",
    "        df = pd.DataFrame({'goals': goals , \n",
    "                           'target': y, \n",
    "                           'predict': pred })\n",
    "        self.targetResults = df.groupby(['target', 'goals'])['goals'].count().unstack('target').fillna(0)\n",
    "        self.predictResults = df.groupby(['predict', 'goals'])['goals'].count().unstack('predict').fillna(0)\n",
    "\n",
    "        \n",
    "    def plotResults(self):\n",
    "        display(self.targetResults)\n",
    "        display(self.predictResults)\n",
    "        \n",
    "        \n",
    "    def printScores(self):      \n",
    "        print ('Scores:\\n\\n    Auroc={:5.3f}  rocauc={:5.3f}  fbeta={:5.3f}  recall={:5.3f}  precision={:5.3f}  Run Time(M)={:5.3f}\\n'.format(\n",
    "                    self.scores['AUROC'], self.scores['rocauc_score'], self.scores['fbeta'], \n",
    "               self.scores['Recall'], self.scores['Precision'], self.scores['RunTime'] ))  \n",
    "        print ('    Best Score={:5.3f}'.format(self.scores['Best Score']))\n",
    "        print ('    Best Params={}'.format(self.scores['Best Params']))\n",
    "        print ('    Goals= {}'.format(self.scores['Goals']))\n",
    "        \n",
    "        \n",
    "    def getScore(self, scoreName=None):\n",
    "        if scoreName:\n",
    "            if scoreName in self.scores:\n",
    "                return self.scores[scoreName]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return self.scores['CM']\n",
    "        \n",
    "    def plotConfusionMatrix(self):\n",
    "        print ()\n",
    "        cmap=plt.cm.Blues\n",
    "        confusionMatrixLabels = [(0,'Paid'), (1, 'Default')]\n",
    "        classes = []\n",
    "        for val, desc in confusionMatrixLabels:\n",
    "            classes.append('{}({})'.format(desc,val))\n",
    "\n",
    "        cm = self.scores['CM']\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def plotroc(self):\n",
    "        print ()\n",
    "        fpr, tpr, thresholds = self.scores['roc_curve']\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % self.scores['AUROC'])\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "        \n",
    "    def showAll(self):\n",
    "        self.printScores()\n",
    "        self.plotConfusionMatrix()\n",
    "        self.plotroc()\n",
    "        self.plotResults()\n",
    "        self.showFeatureImportances()\n",
    "\n",
    "    def showFeatureImportances(self):\n",
    "        if self.scores['FI'] is not None:\n",
    "            print ('Features Importance for ',self.modelName)\n",
    "            (pd.Series(self.scores['FI'], index=dataColumns).nlargest(FEATURESTOREPORT).plot(kind='barh', figsize=(15,10)))\n",
    "            plt.show()\n",
    "        elif self.scores['COEF'] is not None:\n",
    "            # The estimated coefficients will all be around 1:\n",
    "            print('No Feature Importance Using Estimated coefficients')\n",
    "            (pd.Series(self.scores['COEF'], index=dataColumns).nlargest(FEATURESTOREPORT).plot(kind='barh', figsize=(15,10)))\n",
    "            plt.show()\n",
    "        else:\n",
    "            print ('No features to report for ',self.modelName)\n",
    "        return\n",
    "          \n",
    "        \n",
    "        \n",
    "    def logScores(self, runLogName='Test Run', outputFileName='TestRun.csv', verbose=True):\n",
    "        if verbose:\n",
    "            print ('\\nLogging Results: ' + self.modelName)\n",
    "       \n",
    "        results = []\n",
    "              \n",
    "    \n",
    "        hyperparametersToReport = ['loss','max_depth','learning_rate','C','max_iter',\n",
    "                                   'solver','max_features','n_estimators','max_samples',\n",
    "                                   'algorithm','penalty','tol', 'var_smoothing',\n",
    "                                   'min_samples_split','min_samples_leaf','subsample',\n",
    "                                   'validation_fraction','n_iter_no_change',\n",
    "                                   'criterion','splitter']\n",
    " \n",
    "        scoresToReport = ['AUROC','fbeta', 'Recall', 'Precision','RunTime', 'F1', \n",
    "                          'Accuracy', 'MAE', 'r2']\n",
    "    \n",
    "        header = 'Model, Run'\n",
    "        for report in scoresToReport:\n",
    "            header += ', {}'.format(report)\n",
    "            \n",
    "        for param in hyperparametersToReport:\n",
    "            header += ', {}'.format(param)\n",
    "        header += ', runParams'\n",
    "        \n",
    "        if self.hyperparametersBE:\n",
    "            header += ', BaseEstParams'\n",
    "        #print ('\\n')\n",
    "        #print (header)\n",
    "        header+= '\\n'\n",
    "       \n",
    "        # Check is the file exists and than open for write or append\n",
    "        myFile = Path(outputFileName)\n",
    "        if myFile.is_file():\n",
    "            file = open(outputFileName,'a')\n",
    "        else:\n",
    "            file = open(outputFileName,'w')\n",
    "            file.write(header)\n",
    "    \n",
    "    \n",
    "        model = self.clf\n",
    "        scores = self.scores\n",
    "           \n",
    "        # Create a row for the scores\n",
    "        row = '{}, {}'.format(self.modelName, runLogName)\n",
    "        for report in scoresToReport:\n",
    "            if scores[report] is None:\n",
    "                row += ', None'\n",
    "            else:\n",
    "                row += ', {:5.3f}'.format(scores[report])\n",
    "        \n",
    "        # continue on the row with the hyperparametes\n",
    "        \n",
    "        #print ('model.best_params_ = ',model.best_params_)\n",
    "        \n",
    "        # continue on the row with the hyperparametes\n",
    "        for param in hyperparametersToReport:\n",
    "            lookup = lookupModelName(self.modelName.split('+')[0])+param\n",
    "            if lookup in self.bestParams:\n",
    "                row += ', {}'.format(self.bestParams[lookup])\n",
    "            elif param in self.bestParams:\n",
    "                row += ', {}'.format(self.bestParams[param])\n",
    "            else:\n",
    "                row += ','\n",
    "\n",
    "                \n",
    "                \n",
    "        # Format and print the hyperparamaters\n",
    "        hp = self.hyperparameters\n",
    "        hpStr = '{'\n",
    "        for h in hp:\n",
    "            hpStr+='{}: {},'.format(h,hp[h])\n",
    "        hpStr += '}'\n",
    "        row += ',\"{}\"'.format(hpStr)\n",
    "        \n",
    "        # add the base_estimator HPs\n",
    "        if self.hyperparametersBE:\n",
    "            row += ',\"{}\"'.format(self.hyperparametersBE)\n",
    "            \n",
    "        #print (row)\n",
    "        row += '\\n'\n",
    "        file.write(row)\n",
    "           \n",
    "        file.close()\n",
    "        #print ('\\n')\n",
    "        #for x in model.best_params_ :\n",
    "        #    print (x)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for models - Various modes\n",
    "\n",
    "- Short is to run gridsearch on a select # paramaters\n",
    "- Long is a complete range of paramaters to help narrow down\n",
    "- Best has the best paramaters so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters setting done\n"
     ]
    }
   ],
   "source": [
    "# Put in our parameters for classifiers\n",
    "# There are short and long version of hyperparameters based upon the run type\n",
    "\n",
    "############### logisticregression L1 #################\n",
    "# LogisticRegression(penalty=â€™l2â€™, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "# intercept_scaling=1, class_weight=None, random_state=None, solver=â€™warnâ€™, max_iter=100, \n",
    "# multi_class=â€™warnâ€™, verbose=0, warm_start=False, n_jobs=None)[source]\n",
    "#\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# \n",
    "l1_hyperparameters_short = {\n",
    "                'logisticregression__solver' : ['liblinear'],\n",
    "                'logisticregression__max_iter': [10, 15, 25], \n",
    "                'logisticregression__C' : [.01, .1, 10, 50]\n",
    "                 }\n",
    "l1_hyperparameters_long = {\n",
    "                'logisticregression__solver' : ['liblinear', 'saga'],\n",
    "                'logisticregression__C' : [.0001,.001, .01, .1, 10, 30, 50 ,100, 250, 500, 1000],\n",
    "                'logisticregression__max_iter': [15, 25, 50, 100, 300, 500]\n",
    "                }\n",
    "l1_hyperparameters_best = {\n",
    "                'logisticregression__C': [10], \n",
    "                'logisticregression__max_iter': [15], \n",
    "                'logisticregression__solver': ['liblinear']\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "############### logisticregression L2 #################\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "l2_hyperparameters_short = {\n",
    "                'logisticregression__solver' : ['lbfgs', 'liblinear','sag'],\n",
    "                'logisticregression__max_iter': [20, 25, 30], \n",
    "                'logisticregression__C' : [.001, .01, .1, 1.0, 10.]\n",
    "                }\n",
    "l2_hyperparameters_long = {\n",
    "                'logisticregression__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                'logisticregression__C' : [.0001,.001, .01, .1, 10, 50, 100, 250, 500, 1000],\n",
    "                'logisticregression__max_iter': [15, 25, 50, 100, 300, 500]\n",
    "                }\n",
    "l2_hyperparameters_best = {\n",
    "                'logisticregression__C': [.1], \n",
    "                'logisticregression__max_iter': [25], \n",
    "                'logisticregression__solver': ['sag']\n",
    "                }\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "############### randomforestclassifier #################\n",
    "#\n",
    "# RandomForestClassifier(n_estimators=â€™warnâ€™, criterion=â€™giniâ€™, max_depth=None, \n",
    "#      min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#      max_features=â€™autoâ€™, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#      min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "#      n_jobs=None, random_state=None, verbose=0, warm_start=False, \n",
    "#      class_weight=None)\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#\n",
    "rfc_hyperparameters_short = {\n",
    "                'randomforestclassifier__n_estimators': [200, 250],\n",
    "                'randomforestclassifier__max_features': [1.0, .80, 0.33]\n",
    "                }\n",
    "rfc_hyperparameters_long = {\n",
    "                'randomforestclassifier__n_estimators': [10, 50, 100, 200],\n",
    "                'randomforestclassifier__max_features': ['auto', 'sqrt', 0.33, .11, 1.0]\n",
    "                }\n",
    "rfc_hyperparameters_best = {\n",
    "                'randomforestclassifier__n_estimators': [200],\n",
    "                'randomforestclassifier__max_features': [1.0]\n",
    "                }\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "############### gradientboostingclassifier #################\n",
    "#\n",
    "# GradientBoostingClassifier(loss=â€™devianceâ€™, learning_rate=0.1, n_estimators=100, \n",
    "#      subsample=1.0, criterion=â€™friedman_mseâ€™, min_samples_split=2, min_samples_leaf=1,\n",
    "#      min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#      min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
    "#      verbose=0, max_leaf_nodes=None, warm_start=False, presort=â€™autoâ€™, \n",
    "#      validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n",
    "#\n",
    "# https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "#\n",
    "#\n",
    "gbc_hyperparameters_short = {\n",
    "                'gradientboostingclassifier__n_estimators': [300, 500],\n",
    "                'gradientboostingclassifier__min_samples_split': [500],\n",
    "                'gradientboostingclassifier__loss': ['deviance'],\n",
    "                'gradientboostingclassifier__min_samples_leaf': [25],\n",
    "                'gradientboostingclassifier__max_features': ['sqrt'],\n",
    "                'gradientboostingclassifier__max_depth': [6, 8],\n",
    "                'gradientboostingclassifier__learning_rate':[1., .1, .01],\n",
    "                'gradientboostingclassifier__subsample': [.8],\n",
    "                'gradientboostingclassifier__validation_fraction' :[0.1],\n",
    "                'gradientboostingclassifier__n_iter_no_change' :[10],\n",
    "                'gradientboostingclassifier__tol':[0.001]\n",
    "                }\n",
    "gbc_hyperparameters_long = {\n",
    "                'gradientboostingclassifier__min_samples_split': [2, 100, 500],\n",
    "                'gradientboostingclassifier__min_samples_leaf': [1, 50],\n",
    "                'gradientboostingclassifier__max_features': ['sqrt'],\n",
    "                'gradientboostingclassifier__subsample': [1., .8],\n",
    "                'gradientboostingclassifier__n_estimators': [175, 225],\n",
    "                'gradientboostingclassifier__max_depth': [6, 8, 10, 12],\n",
    "                'gradientboostingclassifier__loss': ['exponential','deviance'],\n",
    "                'gradientboostingclassifier__learning_rate':[.2, .1, .01, .05],\n",
    "                'gradientboostingclassifier__validation_fraction' :[0.1],\n",
    "                'gradientboostingclassifier__n_iter_no_change' :[5,10],\n",
    "                'gradientboostingclassifier__tol':[.1, .01, 0.001]\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "gbc_hyperparameters_best = {\n",
    "                'gradientboostingclassifier__n_estimators': [300],\n",
    "                'gradientboostingclassifier__min_samples_split': [500],\n",
    "                'gradientboostingclassifier__loss': ['deviance'],\n",
    "                'gradientboostingclassifier__min_samples_leaf': [25],\n",
    "                'gradientboostingclassifier__max_features': ['sqrt'],\n",
    "                'gradientboostingclassifier__max_depth': [6],\n",
    "                'gradientboostingclassifier__learning_rate':[.1],\n",
    "                'gradientboostingclassifier__subsample': [.8],\n",
    "                'gradientboostingclassifier__validation_fraction' :[0.1],\n",
    "                'gradientboostingclassifier__n_iter_no_change' :[10],\n",
    "                'gradientboostingclassifier__tol':[0.001]\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "############### baggingclassifier #################\n",
    "bagging_hyperparameters_short = {\n",
    "               'baggingclassifier__max_features': [.75, 1.], \n",
    "               'baggingclassifier__max_samples': [.75, 1.], \n",
    "               'baggingclassifier__n_estimators': [50, 100]}\n",
    "\n",
    "bagging_hyperparameters_long = {\n",
    "                'baggingclassifier__n_estimators':[5, 10, 100], \n",
    "                'baggingclassifier__max_samples':[.5, .75, .95, 1.], \n",
    "                'baggingclassifier__max_features':[ .50, .75, .95, 1.]\n",
    "                }\n",
    "bagging_hyperparameters_best = {\n",
    "               'baggingclassifier__max_features': [.75], \n",
    "               'baggingclassifier__max_samples': [.75], \n",
    "               'baggingclassifier__n_estimators': [100]}\n",
    "\n",
    "############### ADABOOST #################\n",
    "adaboost_hyperparameters_short = {'adaboostclassifier__n_estimators':[10, 100], \n",
    "                'adaboostclassifier__learning_rate':[.9, 1.0], \n",
    "                'adaboostclassifier__algorithm':['SAMME.R']}\n",
    "\n",
    "adaboost_hyperparameters_long = {\n",
    "                'adaboostclassifier__n_estimators':[10, 50, 100], \n",
    "                'adaboostclassifier__learning_rate':[.1, 0.5, 1.0], \n",
    "                'adaboostclassifier__algorithm':['SAMME', 'SAMME.R']\n",
    "                }\n",
    "adaboost_hyperparameters_best = {'adaboostclassifier__n_estimators':[100], \n",
    "                'adaboostclassifier__learning_rate':[1.0], \n",
    "                'adaboostclassifier__algorithm':['SAMME.R']}\n",
    "\n",
    "############### gaussiannb #################\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "#\n",
    "# GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "#\n",
    "\n",
    "gaussiannb_hyperparameters_short = {\n",
    "                'gaussiannb__var_smoothing':[ 1.0, .01, .001]\n",
    "                }\n",
    "gaussiannb_hyperparameters_long = {\n",
    "                'gaussiannb__var_smoothing':[ 1., 1e-2, 1e-1, 1e-3, 1e-5, 1e-9]\n",
    "                }\n",
    "gaussiannb_hyperparameters_best = {\n",
    "                'gaussiannb__var_smoothing': [1.0]\n",
    "                }\n",
    " \n",
    "\n",
    "############### gaussiannb #################\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "#\n",
    "# GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "#\n",
    "\n",
    "gpr_hyperparameters_short = {\n",
    "                'gaussianprocessclassifier__max_iter_predict':[100],\n",
    "                'gaussianprocessclassifier__n_restarts_optimizer': [0]\n",
    "                }\n",
    "gpr_hyperparameters_long = {\n",
    "                'gaussianprocessclassifier__max_iter_predict':[50, 100, 200],\n",
    "                'gaussianprocessclassifier__n_restarts_optimizer': [0]\n",
    "                }\n",
    "gpr_hyperparameters_best = {\n",
    "                'gaussianprocessclassifier__max_iter_predict':[100],\n",
    "                'gaussianprocessclassifier__n_restarts_optimizer': [0]\n",
    "                }\n",
    "\n",
    " \n",
    "\n",
    "############### decisiontree #################\n",
    "#\n",
    "#  class sklearn.tree.DecisionTreeClassifier(criterion=â€™giniâ€™, splitter=â€™bestâ€™, \n",
    "#         max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#         max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#         min_impurity_split=None, class_weight=None, presort=False)\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "decisiontree_hyperparameters_short = {'decisiontreeclassifier__splitter': ['best'], \n",
    "                                     'decisiontreeclassifier__min_samples_leaf': [100, 150], \n",
    "                                     'decisiontreeclassifier__min_samples_split': [100, 150], \n",
    "                                     'decisiontreeclassifier__criterion': ['entropy'], \n",
    "                                     'decisiontreeclassifier__max_features': [1.0], \n",
    "                                     'decisiontreeclassifier__max_depth': [10]}\n",
    "decisiontree_hyperparameters_long = {\n",
    "                'decisiontreeclassifier__criterion' :['gini', 'entropy'],\n",
    "                'decisiontreeclassifier__splitter' :['best', 'random'],\n",
    "                'decisiontreeclassifier__min_samples_split' :[2, 50, 100],\n",
    "                'decisiontreeclassifier__min_samples_leaf': [1, 50, 100],\n",
    "                'decisiontreeclassifier__max_features': ['sqrt','auto','log2',1., .2, .5],\n",
    "                'decisiontreeclassifier__max_depth':[None, 1, 10, 50, 100, 250]\n",
    "                }\n",
    "decisiontree_hyperparameters_best = {'decisiontreeclassifier__splitter': ['best'], \n",
    "                                     'decisiontreeclassifier__min_samples_leaf': [100], \n",
    "                                     'decisiontreeclassifier__min_samples_split': [100], \n",
    "                                     'decisiontreeclassifier__criterion': ['entropy'], \n",
    "                                     'decisiontreeclassifier__max_features': [1.0], \n",
    "                                     'decisiontreeclassifier__max_depth': [10]}\n",
    "\n",
    "\n",
    "############### kneighbors #################\n",
    "kneighbors_hyperparameters_short = {}\n",
    "kneighbors_hyperparameters_long = {}\n",
    "kneighbors_hyperparameters_best = {}\n",
    "\n",
    "\n",
    "############### sgdclassifier #################\n",
    "sgd_hyperparameters_short = {\n",
    "                'sgdclassifier__loss': ['hinge'], # \n",
    "                'sgdclassifier__penalty': ['l2'], # 'none', 'l2', 'l1', or 'elasticnet'\n",
    "                'sgdclassifier__max_iter': [1000],\n",
    "                'sgdclassifier__tol': [1e-3 ]\n",
    "                }\n",
    "sgd_hyperparameters_long = {\n",
    "                'sgdclassifier__loss': ['hinge', 'squared_loss', 'perceptron'], # \n",
    "                'sgdclassifier__penalty': ['l2', 'elasticnet'], # 'none', 'l2', 'l1', or 'elasticnet'\n",
    "                'sgdclassifier__max_iter': [10, 100, 1000],\n",
    "                'sgdclassifier__tol': [1e-1 , 1e-2 , 1e-3 ] \n",
    "                }\n",
    "sgd_hyperparameters_best = {\n",
    "                'sgdclassifier__loss': ['perceptron'], # \n",
    "                'sgdclassifier__penalty': ['elasticnet'], # 'none', 'l2', 'l1', or 'elasticnet'\n",
    "                'sgdclassifier__max_iter': [100],\n",
    "                'sgdclassifier__tol': [0.01] \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "############### baggingclassifier #################\n",
    "baggingBE_hyperparameters_short = {\n",
    "               'baggingclassifier__max_features': [1., .75], \n",
    "               'baggingclassifier__max_samples': [1., .75], \n",
    "               'baggingclassifier__n_estimators': [10, 100]}\n",
    "\n",
    "baggingBE_hyperparameters_long = {\n",
    "                'baggingclassifier__n_estimators':[5, 10, 100], \n",
    "                'baggingclassifier__max_samples':[.5, .75, .95, 1.], \n",
    "                'baggingclassifier__max_features':[ .50, .75, .95, 1.]\n",
    "                }\n",
    "\n",
    "baggingBE_hyperparameters_best = {\n",
    "               'baggingclassifier__max_features': [.75], \n",
    "               'baggingclassifier__max_samples': [.75], \n",
    "               'baggingclassifier__n_estimators': [100]}\n",
    "\n",
    "\n",
    "############### ADABOOST #################\n",
    "adaboostBE_hyperparameters_short = {'adaboostclassifier__n_estimators':[10, 100], \n",
    "                'adaboostclassifier__learning_rate':[.1, .5, 1.0], \n",
    "                'adaboostclassifier__algorithm':['SAMME.R']}\n",
    "\n",
    "adaboostBE_hyperparameters_long = {\n",
    "                'adaboostclassifier__n_estimators':[10, 50, 100], \n",
    "                'adaboostclassifier__learning_rate':[.1, 0.5, 1.0], \n",
    "                'adaboostclassifier__algorithm':['SAMME', 'SAMME.R']\n",
    "                }\n",
    "adaboostBE_hyperparameters_best = {'adaboostclassifier__n_estimators':[100], \n",
    "                'adaboostclassifier__learning_rate':[1.0], \n",
    "                'adaboostclassifier__algorithm':['SAMME.R']}\n",
    "\n",
    "\n",
    "\n",
    "print ('Hyperparameters setting done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters setting done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparameters_short = {'l1':l1_hyperparameters_short, 'l2':l2_hyperparameters_short, \n",
    "                         'rfc':rfc_hyperparameters_short, 'gbc':gbc_hyperparameters_short, \n",
    "                         'decisiontree':decisiontree_hyperparameters_short, \n",
    "                         'kneighbors':kneighbors_hyperparameters_short, \n",
    "                         'sgd':sgd_hyperparameters_long, \n",
    "                         'gpr':gpr_hyperparameters_long, \n",
    "                         'bagging':bagging_hyperparameters_short, \n",
    "                         'adaboost':adaboost_hyperparameters_short,\n",
    "                         'baggingBE':bagging_hyperparameters_short, \n",
    "                         'adaboostBE':adaboost_hyperparameters_short,\n",
    "                         'gaussiannb': gaussiannb_hyperparameters_short}\n",
    "\n",
    "\n",
    "hyperparameters_long = {'l1':l1_hyperparameters_long, 'l2':l2_hyperparameters_long, \n",
    "                        'rfc':rfc_hyperparameters_long, 'gbc':gbc_hyperparameters_long, \n",
    "                        'decisiontree':decisiontree_hyperparameters_long, \n",
    "                        'kneighbors':kneighbors_hyperparameters_long, \n",
    "                        'sgd':sgd_hyperparameters_long, \n",
    "                        'gpr':gpr_hyperparameters_long, \n",
    "                        'bagging':bagging_hyperparameters_long, \n",
    "                        'adaboost':adaboost_hyperparameters_long,\n",
    "                        'baggingBE':bagging_hyperparameters_long, \n",
    "                        'adaboostBE':adaboost_hyperparameters_long,\n",
    "                        'gaussiannb': gaussiannb_hyperparameters_long}\n",
    "\n",
    "hyperparameters_best = {'l1':l1_hyperparameters_best, 'l2':l2_hyperparameters_best, \n",
    "                        'rfc':rfc_hyperparameters_best, 'gbc':gbc_hyperparameters_best, \n",
    "                        'decisiontree':decisiontree_hyperparameters_best, \n",
    "                        'kneighbors':kneighbors_hyperparameters_best, \n",
    "                        'sgd':sgd_hyperparameters_best, \n",
    "                        'gpr':gpr_hyperparameters_best, \n",
    "                        'bagging':bagging_hyperparameters_best, \n",
    "                        'adaboost':adaboost_hyperparameters_best,\n",
    "                        'baggingBE':bagging_hyperparameters_best, \n",
    "                        'adaboostBE':adaboost_hyperparameters_best,\n",
    "                        'gaussiannb': gaussiannb_hyperparameters_best}\n",
    "\n",
    "\n",
    "models = {'l1':LogisticRegression(penalty='l1', random_state=SEED, n_jobs=-2), \n",
    "          'l2': LogisticRegression(penalty='l2', random_state=SEED, n_jobs=-2), \n",
    "          'rfc': RandomForestClassifier(random_state=SEED, n_jobs=-2), \n",
    "          'gbc': GradientBoostingClassifier(random_state=SEED),\n",
    "          'decisiontree': DecisionTreeClassifier(random_state=SEED),\n",
    "          'kneighbors': KNeighborsClassifier(n_jobs=-2), \n",
    "          'sgd': SGDClassifier(random_state=SEED, n_jobs=-2),\n",
    "          'bagging': BaggingClassifier(random_state=SEED, n_jobs=-2),\n",
    "          'adaboost': AdaBoostClassifier(random_state=SEED),\n",
    "          'gaussiannb': GaussianNB()\n",
    "          }\n",
    "\n",
    "def get_feature_importance(self, clf, modelName ):\n",
    "        clfs = {'rfc':'feature_importances',\n",
    "                'adaboost': 'feature_importances',\n",
    "                'l1': 'coef',\n",
    "                'l2': 'coef',\n",
    "                'sgd': 'coef',\n",
    "                'bagging': None, \n",
    "                'gbc': 'feature_importances',\n",
    "                'gpr': None,\n",
    "                'gaussiannb': None,\n",
    "                'decisiontree': 'feature_importances',\n",
    "                'kneighbors': None}\n",
    "\n",
    "        if clfs[modelName] == 'feature_importances':\n",
    "            return  list(clf.feature_importances_)\n",
    "        elif clfs[modelName] == 'coef':\n",
    "            return  list(clf.coef_.tolist())\n",
    "        else:\n",
    "            return None \n",
    "\n",
    "print ('Hyperparameters setting done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to Rock and Roll\n"
     ]
    }
   ],
   "source": [
    "# Build a model based upon the model type (model with a base_estimator i.e. baggingBE)\n",
    "# theModel is ('modelname': 'Base estimator Name if there is one')\n",
    "\n",
    "def fixHyperparameters(params, useList=False):\n",
    "    cleanParam = {}\n",
    "    for p in params:\n",
    "        paramName = p.split('__',1)[1]\n",
    "        if useList:\n",
    "            value = params[p]\n",
    "        else:\n",
    "            value = params[p][0]\n",
    "        cleanParam[paramName] = value\n",
    "    return cleanParam\n",
    "\n",
    "def buildModel (theModel):\n",
    "    \n",
    "    modelName, modelNameBE = theModel\n",
    "\n",
    "    if modelName in beModels and modelNameBE is not None:\n",
    "        baseModel = modelName+'BE'\n",
    "    else:\n",
    "        baseModel = modelName\n",
    "\n",
    "    if whatAreWeRunning==RUNSHORT:\n",
    "        params =  hyperparameters_short[baseModel]\n",
    "    elif whatAreWeRunning==RUNLONG:\n",
    "        params =  hyperparameters_long[baseModel]\n",
    "    elif whatAreWeRunning==RUNBEST:\n",
    "        params =  hyperparameters_best[baseModel]\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    BEparams = None\n",
    "    if modelName in beModels and modelNameBE is not None:\n",
    "        BE = models[modelNameBE]\n",
    "        if whatAreWeRunning==RUNDEFAULT:\n",
    "            BEparams =  {}\n",
    "        else:\n",
    "            BEparams =  hyperparameters_best[modelNameBE]       \n",
    "        \n",
    "       \n",
    "        cleanBEparams = fixHyperparameters(BEparams, useList=False)\n",
    "        BE.set_params(**cleanBEparams)\n",
    "        \n",
    "        if modelName == 'bagging':\n",
    "            model = BaggingClassifier(base_estimator=BE, random_state=SEED)\n",
    "        elif modelName == 'adaboost':\n",
    "            model = AdaBoostClassifier(base_estimator=BE, random_state=SEED)\n",
    "        else:\n",
    "            pass # Error \n",
    "    else:\n",
    "        model = models[modelName]\n",
    "    return model, params #, BEparams\n",
    "\n",
    "\n",
    "\n",
    "print ('Ready to Rock and Roll')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to run:  {'meta-logisticregression__C': [0.1], 'meta-logisticregression__solver': ['sag'], 'meta-logisticregression__max_iter': [25]}\n"
     ]
    }
   ],
   "source": [
    "# Build the pipeline of selected models and hyperparameters\n",
    "\n",
    "stackingModel = ('l2', None)\n",
    "\n",
    "#\n",
    "modelList2Run \n",
    "\n",
    "\n",
    "\n",
    "paramsList = {}\n",
    "runModels =[]\n",
    "runStackParams = {}\n",
    "\n",
    "for theModel in modelList2Run:\n",
    "    modelName, BEname = theModel\n",
    "    if BEname is not None:\n",
    "        modelName += '+' + BEname\n",
    "    \n",
    "    M, P = buildModel(theModel)\n",
    "    P = fixHyperparameters(P, useList=False)\n",
    "    M.set_params(**P)\n",
    "    \n",
    "    # Build the param list and place the model on the list of models to run\n",
    "    #for p in P:\n",
    "    #    paramsList[p] = P[p]\n",
    "    runModels.append(M)\n",
    "    runStackParams[modelName] = P\n",
    "   \n",
    " \n",
    "metaClassifierModel, P = buildModel(stackingModel)\n",
    "for p in P:\n",
    "#    print ('this is p=',p, P[p])\n",
    "    paramsList['meta-'+p] = P[p]\n",
    "#    print (\"meta-+p\", 'meta-'+p)\n",
    "#    print ('paramsList[\"meta-\"+p]',paramsList['meta-'+p])\n",
    "    \n",
    "stackingModelName,_ = stackingModel\n",
    "\n",
    "print ('Params to run: ', paramsList)\n",
    "#print ('\\n\\nmodels to run: ', runModels)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adaboost+gbc': {'algorithm': 'SAMME.R',\n",
       "  'learning_rate': 1.0,\n",
       "  'n_estimators': 100},\n",
       " 'bagging+gbc': {'max_features': 0.75,\n",
       "  'max_samples': 0.75,\n",
       "  'n_estimators': 100},\n",
       " 'gaussiannb': {'var_smoothing': 1.0},\n",
       " 'l2': {'C': 0.1, 'max_iter': 25, 'solver': 'sag'},\n",
       " 'sgd': {'loss': 'perceptron',\n",
       "  'max_iter': 100,\n",
       "  'penalty': 'elasticnet',\n",
       "  'tol': 0.01}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runStackParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Grade from the X Dataset for latter comparing to the end results\n",
    "grade = X['grade']\n",
    "X.drop('grade', axis = 1, inplace=True)\n",
    "\n",
    "# Need to track the columns to be used in  reporting feature importance\n",
    "dataColumns = X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the data and make the scorers\n",
    "if useStandardScaler:\n",
    "    # Fix to flow for standard scaler\n",
    "    for col in X:\n",
    "        X[col].astype('float64', inplace=True)\n",
    "    X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 134024 Records\n"
     ]
    }
   ],
   "source": [
    "# Make a much smaller dataset to run debug / calabration runs\n",
    "if SMALLDATA:\n",
    "    Xs, _ , ys, _        = train_test_split(X, y, test_size=SMALLDATASIZE, random_state=SEED)\n",
    "    tempS, _ , grade_test,_  = train_test_split(X, grade, test_size=SMALLDATASIZE, random_state=SEED)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=TESTSIZE, random_state=SEED)\n",
    "    _, _, _, grade = train_test_split(tempS, grade_test, test_size=TESTSIZE, random_state=SEED)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TESTSIZE, random_state=SEED)\n",
    "    _,_,_,grade = train_test_split(X, grade, test_size=TESTSIZE, random_state=SEED)\n",
    "\n",
    "    \n",
    "fbetaScorer = make_scorer(fbeta_score, beta=FBETA)\n",
    "print ('Running for {} Records'.format(len(X_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fitting: l2\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed: 36.7min remaining: 36.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a79cc02b30cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                     refit=True)\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mrunTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrunTimeStart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/site-packages/sklearn/externals/joblib/externals/loky/_base.pyc\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python27/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sclf = StackingClassifier(classifiers=runModels, \n",
    "                          use_probas = True,\n",
    "                          average_probas=True,\n",
    "                          meta_classifier=metaClassifierModel)\n",
    "\n",
    "runTimeStart = time()\n",
    "print ('\\n\\nFitting: '+stackingModelName)\n",
    "\n",
    "if crossValidationSplits:\n",
    "    setCV = crossValidationSplits\n",
    "else:\n",
    "    setCV = len(modelList2Run)+1\n",
    "\n",
    "    \n",
    "pList = {'meta-gaussiannb__var_smoothing': [1e-07], \n",
    "         'max_iter': [15]}    \n",
    "    \n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=paramsList, \n",
    "#                    param_grid=pList, \n",
    "                    cv=setCV,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = fbetaScorer,\n",
    "                    verbose = gridSearchVerbose,\n",
    "                    refit=True)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "runTime = time() - runTimeStart\n",
    "\n",
    "\n",
    "# Log/print the scores\n",
    "gridScore=calcScores(grid, stackingModelName, paramsList, None, X_test, y_test, runTime, grade)\n",
    "gridScore.printScores()\n",
    "gridScore.logScores(runLogName, logFileName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridScore.showAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runLogName += '; Classifier'\n",
    "\n",
    "for model, theModel in zip(runModels, modelList2Run):\n",
    "    name, BEname = theModel\n",
    "    if BEname is not None:\n",
    "        name += '+' + BEname\n",
    " \n",
    "    print ('\\nFit and Scoring ', name)\n",
    "    model.fit(X_train, y_train)\n",
    "    stackScore=calcScores(model, name, runStackParams[name], None, X_test, y_test, 0, grade)\n",
    "    stackScore.logScores(runLogName, logFileName)\n",
    "    stackScore.showAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
